{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# list of file name strings from S1 and S2\n",
    "S1_files = [\"../S1_Dataset/\" + file for file in os.listdir(\"../S1_Dataset\") if os.path.isfile]\n",
    "S2_files = [\"../S2_Dataset/\" + file for file in os.listdir(\"../S2_Dataset\") if os.path.isfile]\n",
    "\n",
    "# TODO: when done with program, merge all data from S1 and S2 into 1 giant dataset\n",
    "# for testing only using 1 file for now\n",
    "file = S1_files[0]\n",
    "\n",
    "df = pd.read_csv(file, header=None)\n",
    "df.columns = [\n",
    "    'time',\n",
    "    'frontal accel',\n",
    "    'vertical accel',\n",
    "    'lateral accel',\n",
    "    'antenna id',\n",
    "    'rssi',\n",
    "    'phase',\n",
    "    'frequency',\n",
    "    'activity',\n",
    "]\n",
    "activities = {\n",
    "    1: 'sit on bed',\n",
    "    2: 'sit on chair',\n",
    "    3: 'lying',\n",
    "    4: 'ambulating',\n",
    "}\n",
    "df.replace({'activity': activities}, inplace=True)\n",
    "\n",
    "# TODO: select and add any new features to df\n",
    "\n",
    "# TODO: preprocess data and split into test and training sets using df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building + Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# TODO: add hyperparameters that we will be testing as parameters for this function\n",
    "def create_model(): \n",
    "    print(\"NOT IMPLEMENTED\")\n",
    "    # TODO: implement our nueral network structure using SGD as the optimization technique\n",
    "\n",
    "    # maybe use tf.keras.sequential here?\n",
    "    model = 0\n",
    "    return model\n",
    "    \n",
    "# TODO: add hyper parameters that we will be testing to param_grid \n",
    "param_grid = {\n",
    "\n",
    "}\n",
    "\n",
    "keras_model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# TODO: for GridSearchCV modify any other params that we need (scoring, cv, num_jobs, etc)\n",
    "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: implement model evaluation and print/graph anything needed for visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
