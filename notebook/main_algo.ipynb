{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing  \n",
    "Sofia, Angel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile, ZipInfo\n",
    "import pandas as pd\n",
    "\n",
    "## this is the zipped folder name on my computer, idk if its the same for everyone\n",
    "zipped_name = 'activity+recognition+with+healthy+older+people+using+a+batteryless+wearable+sensor.zip'\n",
    "\n",
    "## honestly, idk what this is doing, but i feel its important stuff\n",
    "z = ZipFile(zipped_name, 'r')\n",
    "ls1 = z.infolist()\n",
    "ls2 = [file for file in ls1 if file.file_size > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## im going to seperate the files into four categories to make adding extra attributes easier\n",
    "S1F = []\n",
    "S1M = []\n",
    "S2F = []\n",
    "S2M = []\n",
    "## this one is just to check my work\n",
    "other = [] #ignore\n",
    "\n",
    "## i feel like there was a more efficient way to do this\n",
    "## but this segment of code extracts the content of the files\n",
    " # and converts them into pandas dataframes\n",
    "for i in range(len(ls2)):\n",
    "    temp_zip = z.extract(member=ls2[i])\n",
    "    if ((\"S1_Dataset\" in temp_zip) and (\"F\" in temp_zip)):\n",
    "        temp_csv = pd.read_csv(temp_zip, header=None)\n",
    "        S1F.append(temp_csv)\n",
    "    elif ((\"S1_Dataset\" in temp_zip) and ('M' in temp_zip) and ('.txt' not in temp_zip)):\n",
    "        temp_csv = pd.read_csv(temp_zip, header=None)\n",
    "        S1M.append(temp_csv)\n",
    "    elif ((\"S2_Dataset\" in temp_zip) and (\"F\" in temp_zip)):\n",
    "        temp_csv = pd.read_csv(temp_zip, header=None)\n",
    "        S2F.append(temp_csv)\n",
    "    elif ((\"S2_Dataset\" in temp_zip) and (\"M\" in temp_zip) and ('.txt' not in temp_zip)):\n",
    "        temp_csv = pd.read_csv(temp_zip, header=None)\n",
    "        S2M.append(temp_csv)\n",
    "    else:\n",
    "        other.append(temp_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all dataframes in one list, seperated into four categories\n",
    " # (based on gender and room)\n",
    "all_datasets = [S1F, S1M, S2F, S2M]\n",
    "\n",
    "features = [\n",
    "    'time',\n",
    "    'frontal accel',\n",
    "    'vertical accel',\n",
    "    'lateral accel',\n",
    "    'antenna id',\n",
    "    'rssi',\n",
    "    'phase',\n",
    "    'frequency',\n",
    "    'activity',\n",
    "]\n",
    "\n",
    "activities = [\n",
    "    'sitting on bed',\n",
    "    'sitting on chair',\n",
    "    'lying',\n",
    "    'ambulating'\n",
    "]\n",
    "\n",
    "## in this segment of code, i rename the headers\n",
    "new_headers = dict(enumerate(features))\n",
    "for subset in all_datasets:\n",
    "    for df in subset:\n",
    "        df.rename(columns = new_headers, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  CAN ONLY RUN ONCE APPARENTLY\n",
    "##\n",
    "\n",
    "## adding F/M and room columns to dataframes F=0 and M=1 \n",
    "for df in S1F:\n",
    "    df.insert(len(df.columns) - 1, 'gender', 0)\n",
    "    df.insert(1, 'room', 1)\n",
    "\n",
    "for df in S1M:\n",
    "    df.insert(len(df.columns) - 1, 'gender', 1)\n",
    "    df.insert(1, 'room', 1)\n",
    "\n",
    "for df in S2F:\n",
    "    df.insert(len(df.columns) - 1, 'gender', 0)\n",
    "    df.insert(1, 'room', 2)\n",
    "\n",
    "for df in S2M:\n",
    "    df.insert(len(df.columns) - 1, 'gender', 1)\n",
    "    df.insert(1, 'room', 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go through each dataframe and add additional columns now. In these next cells, I add the 'consecutiveness' feature. This tells us how many times in a row an individual did an activity. \n",
    "\n",
    "For example, the first observation will have a 1 in this column. If the individual continued to do the same activity in the next observation, that obervation will have a 2 for the 'consecutivness' feature.\n",
    "Otherwise, the count will start over at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to add in the 'consecutiveness' attribute in a dataframe\n",
    "def count_activities(dataframe):\n",
    "    counts = []\n",
    "    curr_count = 0\n",
    "    prev_act = None\n",
    "\n",
    "    for act in df['activity']:\n",
    "        if act == prev_act:\n",
    "            curr_count += 1\n",
    "        else:\n",
    "            curr_count = 1\n",
    "            prev_act = act\n",
    "    \n",
    "        counts.append(curr_count)\n",
    "\n",
    "    dataframe.insert(len(dataframe.columns) - 1, 'consecutiveness', counts)\n",
    "    return dataframe\n",
    "\n",
    "list_of_dataframes = S1F + S1M + S2F + S2M\n",
    "\n",
    "##   ONLY RUN ONCE\n",
    "##\n",
    "\n",
    "## adds the column 'consecutiveness' into each dataframe\n",
    "for df in list_of_dataframes:\n",
    "    count_activities(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section of code adds the acceleration column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def calc_and_add_accel(dataframe):\n",
    "    acceleration = []\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        fa = dataframe['frontal accel'][i]\n",
    "        la = dataframe['lateral accel'][i]\n",
    "        va = dataframe['vertical accel'][i]\n",
    "\n",
    "        accel_vector = np.sqrt(fa**2 + la**2 + va**2)\n",
    "        acceleration.append(accel_vector)\n",
    "\n",
    "    dataframe['acceleration'] = acceleration\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JUST RUN ONCE\n",
    "\n",
    "for df in list_of_dataframes:\n",
    "    calc_and_add_accel(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added binary activity status in the last column. 0 = non-active, 1 = active\n",
    "\n",
    "\n",
    "I also combined all observations into one large dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df = pd.concat(list_of_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = large_df.shape[0]\n",
    "\n",
    "bed = (large_df['activity'] == 1).sum() / totals\n",
    "chair = (large_df['activity'] == 2).sum() / totals\n",
    "lying = (large_df['activity'] == 3).sum() / totals \n",
    "amb = (large_df['activity'] == 4).sum() / totals \n",
    "\n",
    "act_dict = {1: bed, 2: chair, 3: lying, 4: amb}\n",
    "\n",
    "large_df['freq'] = large_df['activity'].map(act_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_activity = []\n",
    "for i in range(large_df.shape[0]):\n",
    "    if large_df['activity'][i] in range(0,4):\n",
    "        binary_activity.append(0)\n",
    "    else:\n",
    "        binary_activity.append(1)\n",
    "\n",
    "## ONLY RUN ONCE\n",
    "    # or run from the top if needed\n",
    "\n",
    "large_df.insert(len(large_df.columns), 'status', binary_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nomralize RSSI [-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,0))\n",
    "large_df['rssi'] = scaler.fit_transform(large_df[['rssi']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>room</th>\n",
       "      <th>frontal accel</th>\n",
       "      <th>vertical accel</th>\n",
       "      <th>lateral accel</th>\n",
       "      <th>antenna id</th>\n",
       "      <th>rssi</th>\n",
       "      <th>phase</th>\n",
       "      <th>frequency</th>\n",
       "      <th>gender</th>\n",
       "      <th>consecutiveness</th>\n",
       "      <th>activity</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>freq</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>-0.547296</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.948012</td>\n",
       "      <td>1.527441</td>\n",
       "      <td>0.386985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.582090</td>\n",
       "      <td>1.194140</td>\n",
       "      <td>-1.441573</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.822632</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.567449</td>\n",
       "      <td>-1.249305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30968</th>\n",
       "      <td>0.386479</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501053</td>\n",
       "      <td>-0.911475</td>\n",
       "      <td>0.386985</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.701493</td>\n",
       "      <td>-1.198657</td>\n",
       "      <td>-1.441573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.797232</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.832855</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41084</th>\n",
       "      <td>0.268617</td>\n",
       "      <td>1</td>\n",
       "      <td>1.370512</td>\n",
       "      <td>-1.021089</td>\n",
       "      <td>0.465048</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.731343</td>\n",
       "      <td>0.854630</td>\n",
       "      <td>0.047326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099384</td>\n",
       "      <td>3</td>\n",
       "      <td>1.840302</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>-0.139534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.761987</td>\n",
       "      <td>-0.336004</td>\n",
       "      <td>0.178808</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.522388</td>\n",
       "      <td>1.376200</td>\n",
       "      <td>-1.441573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945201</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.446581</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51649</th>\n",
       "      <td>-0.447880</td>\n",
       "      <td>1</td>\n",
       "      <td>1.515352</td>\n",
       "      <td>-1.021089</td>\n",
       "      <td>0.386985</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.537313</td>\n",
       "      <td>-0.921696</td>\n",
       "      <td>1.834004</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.494973</td>\n",
       "      <td>3</td>\n",
       "      <td>2.457825</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57371</th>\n",
       "      <td>0.257937</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.716170</td>\n",
       "      <td>-0.034554</td>\n",
       "      <td>-1.694730</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.268657</td>\n",
       "      <td>0.217766</td>\n",
       "      <td>-1.441573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292424</td>\n",
       "      <td>3</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62750</th>\n",
       "      <td>1.832676</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.034965</td>\n",
       "      <td>0.047634</td>\n",
       "      <td>-1.798696</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.417910</td>\n",
       "      <td>-0.597674</td>\n",
       "      <td>-0.250454</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.418774</td>\n",
       "      <td>3</td>\n",
       "      <td>0.157947</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>-0.906321</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.440714</td>\n",
       "      <td>1.582185</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.537313</td>\n",
       "      <td>1.251787</td>\n",
       "      <td>-1.441573</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.881052</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.730638</td>\n",
       "      <td>-1.249305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45183</th>\n",
       "      <td>-0.858555</td>\n",
       "      <td>1</td>\n",
       "      <td>1.196507</td>\n",
       "      <td>-0.445611</td>\n",
       "      <td>-0.107419</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.597015</td>\n",
       "      <td>0.697865</td>\n",
       "      <td>-1.441573</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.875972</td>\n",
       "      <td>3</td>\n",
       "      <td>1.484812</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42612</th>\n",
       "      <td>-0.695838</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.136267</td>\n",
       "      <td>1.637072</td>\n",
       "      <td>0.647199</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.671642</td>\n",
       "      <td>-0.827528</td>\n",
       "      <td>0.345106</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.807392</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.527925</td>\n",
       "      <td>-1.249305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75128 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  room  frontal accel  vertical accel  lateral accel  \\\n",
       "18181 -0.547296     1      -0.948012        1.527441       0.386985   \n",
       "30968  0.386479     1       0.501053       -0.911475       0.386985   \n",
       "41084  0.268617     1       1.370512       -1.021089       0.465048   \n",
       "7373  -0.139534     1       0.761987       -0.336004       0.178808   \n",
       "51649 -0.447880     1       1.515352       -1.021089       0.386985   \n",
       "...         ...   ...            ...             ...            ...   \n",
       "57371  0.257937     2      -0.716170       -0.034554      -1.694730   \n",
       "62750  1.832676     2      -1.034965        0.047634      -1.798696   \n",
       "4777  -0.906321     1      -1.440714        1.582185       0.204845   \n",
       "45183 -0.858555     1       1.196507       -0.445611      -0.107419   \n",
       "42612 -0.695838     1      -2.136267        1.637072       0.647199   \n",
       "\n",
       "       antenna id      rssi     phase  frequency  gender  consecutiveness  \\\n",
       "18181           1 -0.582090  1.194140  -1.441573       0        -0.822632   \n",
       "30968           4 -0.701493 -1.198657  -1.441573       1        -0.797232   \n",
       "41084           1 -0.731343  0.854630   0.047326       1         0.099384   \n",
       "7373            1 -0.522388  1.376200  -1.441573       0         0.945201   \n",
       "51649           3 -0.537313 -0.921696   1.834004       1        -0.494973   \n",
       "...           ...       ...       ...        ...     ...              ...   \n",
       "57371           2 -0.268657  0.217766  -1.441573       0         0.292424   \n",
       "62750           2 -0.417910 -0.597674  -0.250454       0        -0.418774   \n",
       "4777            4 -0.537313  1.251787  -1.441573       0        -0.881052   \n",
       "45183           3 -0.597015  0.697865  -1.441573       1        -0.875972   \n",
       "42612           1 -0.671642 -0.827528   0.345106       1        -0.807392   \n",
       "\n",
       "       activity  acceleration      freq  status  \n",
       "18181         1     -0.567449 -1.249305       0  \n",
       "30968         3     -1.832855  0.666497       0  \n",
       "41084         3      1.840302  0.666497       0  \n",
       "7373          3     -0.446581  0.666497       0  \n",
       "51649         3      2.457825  0.666497       0  \n",
       "...         ...           ...       ...     ...  \n",
       "57371         3      0.060519  0.666497       0  \n",
       "62750         3      0.157947  0.666497       0  \n",
       "4777          1     -0.730638 -1.249305       0  \n",
       "45183         3      1.484812  0.666497       0  \n",
       "42612         1     -0.527925 -1.249305       0  \n",
       "\n",
       "[75128 rows x 15 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function normalizes columns using z-score\n",
    "\n",
    "def z_standardize(dataframe, *columns):\n",
    "    for column in columns:\n",
    "        col = str(column)\n",
    "        dataframe[col] = (dataframe[col] - dataframe[col].mean()) / dataframe[col].std()\n",
    "    return dataframe\n",
    "\n",
    "# normalized most columns\n",
    "# \".sample(frac=1)\" part of the function just shuffles the data points around\n",
    "    # can delete that part if needed\n",
    "z_standardize(large_df, 'time', 'frontal accel', 'vertical accel', 'lateral accel', 'phase', 'frequency', 'consecutiveness', 'acceleration', 'freq').sample(frac=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = large_df.drop(columns=['status'])\n",
    "y = large_df['status']\n",
    "train_data, test_data = train_test_split(X, test_size=0.25, random_state=42)\n",
    "train_label, test_label = train_test_split(y, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building + Testing Model\n",
    "\n",
    "**Hyper param testing**  \n",
    "Martin  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# TODO: add hyperparameters that we will be testing as parameters for this function (Martin)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(): \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.wrappers'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# TODO: add hyperparameters that we will be testing as parameters for this function (Martin)\n",
    "def create_model(): \n",
    "    print(\"NOT IMPLEMENTED\")\n",
    "    # TODO: implement our nueral network structure using SGD as the optimization technique (Martin)\n",
    "\n",
    "    # maybe use tf.keras.sequential here?\n",
    "    model = 0\n",
    "    return model\n",
    "    \n",
    "# TODO: add hyper parameters that we will be testing to param_grid (Martin)\n",
    "param_grid = {\n",
    "    \"activation\"\n",
    "}\n",
    "\n",
    "keras_model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# TODO: for GridSearchCV modify any other params that we need (scoring, cv, num_jobs, etc) (Martin)\n",
    "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: implement model evaluation and print/graph anything needed for visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
